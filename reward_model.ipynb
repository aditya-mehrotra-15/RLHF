{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V5E1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qyiIULcfShON"
   },
   "outputs": [],
   "source": [
    "!pip install -q \"transformers>=4.35.0\" accelerate bitsandbytes peft trl datasets sentencepiece torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch, os\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "BASE_MODEL = \"mistralai/Mistral-7B-v0.3\"\n",
    "SFT_ADAPTER_DIR = \"coqa_chatbot_lora\"\n",
    "\n",
    "REWARD_MODEL_DIR = \"reward_model\"\n",
    "PPO_OUTPUT_DIR = \"ppo_output\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdoTwFHQaH8n",
    "outputId": "bdd8f58e-3ef7-4423-a54b-83d3d1a01cf6"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from pathlib import Path\n",
    "\n",
    "def load_sft_model(adapter_dir=SFT_ADAPTER_DIR, base_model=BASE_MODEL):\n",
    "    \"\"\"\n",
    "    Loads the 4-bit base model and applies the LoRA adapters saved from SFT.\n",
    "    Mirrors exactly what your SFT notebook did.\n",
    "    \"\"\"\n",
    "    print(f\"Loading base model {base_model} in 4-bit and applying adapters from {adapter_dir}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=False, trust_remote_code=True)\n",
    "    base = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        use_cache=False,\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(base, adapter_dir, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "# Load SFT model check\n",
    "tok, _ = load_sft_model()\n",
    "print(\"\u2705 Loaded SFT model + tokenizer\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403,
     "referenced_widgets": [
      "26a6203a250e421e9e57818a7388267b",
      "85a98490508d434597146946ba89b0c0",
      "9bcb23aa7c0b4b08b32e53ad93b5f841",
      "d854f04b8bd4482c8e74698f642307f4",
      "03c4029ee30144e1af15a71b1395b2ec",
      "ca18d6cf84404d96ad7a8b94e2f8b3ea",
      "b10c64e7c3614285ad962a8f2baa3719",
      "ae8270156cbe4d7cb24a3003c8369574",
      "dde11bb0426e4fe8b4e9507a2e4d223b",
      "b6b40a4484f34171ac761d35ce87446b",
      "cfa4562dd61e4654ac8cfef0cf4fba38",
      "957615421d6848cbab8add7e580082d8",
      "decb3bcc82124070b99cbb296532d528",
      "e102a67e03de470387e0783b4a490228",
      "15f8794e8ca14dd6b2b9c7b9f8ac6780",
      "868f7b17d57c4d34b627a2b84d71d938",
      "641b443ebd674b43b77770d540d679ee",
      "878dd39b69c64a5188848eabc1f60806",
      "7031d0908193436a979883679ec4e8b9",
      "dd504d2daa57426780bfbd78370d054d",
      "b390d715800641f49dc15084e3806f43",
      "0df3bda582094ba39b38e630672f3fb5",
      "3915ea43b8f8424c88d2b532d04f1b18",
      "1fc0cc34e2794142b830e4d51f4c2355",
      "a6492b7dc4954a91beba6b08a2859500",
      "9678cd396ef14c99a0f2bd7cbee07147",
      "d5b426bcd178421786c35cc1d8686287",
      "8172ee31c324419cbf8855859f4f9a70",
      "064c51dacd264991a3d749323b29f268",
      "ab928e24c7b646fa86e45dbdbbf3b2e3",
      "a0d5b3982a1e4b6daa37c07a6cdb6b4c",
      "69e4aa3b99c64a3fbf673875aaee23b9",
      "0d42c7d1bb0f46b5b65195aafe38c4cc",
      "d8bd568875e24fb5a921cdf1b1982041",
      "3b0f3bffd1b64901a451850603d448d0",
      "370ea0f127cd4994a37e4ee05766b1a2",
      "15369b9ab72b4a769e5b699649716344",
      "64a22bf6bb234a41b5c79bbd715706c8",
      "041c178dcbab4f8db0136842cb304c42",
      "a036e903b35d4efdb46a29882f1f2ae5",
      "62fd7627e5514b219517bead1c1b7e75",
      "810f9a68042440ff8d30378bec65ebc0",
      "5907f4ef7ead43e1a601cad9f2046737",
      "12362a7ccd90420284bb5ae32b115085",
      "35dbb886f2cb4207ab4677777f01120c",
      "aad653edd17d4713958aeb5ac555f6ae",
      "99581f95647f4ec7914091a54d66aa85",
      "a4356403f5764080a88cad5db88fdeb6",
      "57f5be65e1574f15badb2712d8342fbf",
      "529382c633fc4b0a8b3859312a80a08c",
      "b5819e5b04764fc3a3ec3f29c1df9694",
      "8ec7882521494278a2f0ab95f1095109",
      "98c6812f522e4c1aaec517ff25de6416",
      "726cf91cd91849d0a674d29cb6f937c0",
      "8f9f33e8017c425784f14d74b0e85d8c",
      "d5b86f5b70f64555a1f71b6e8decd7ea",
      "ae6570fb22c342fc9dafe39d1a0fed94",
      "f025f6b5df58433eb76481deb9952a4b",
      "8e3573ca6904453c853e6b9605a9187b",
      "733f1999fa2f49cc8a70e0591d340701",
      "8c704e4623014a5fb02937728a45c9e8",
      "bbb5ebc48a8140dd8ced2199f3715f43",
      "d3fcb4550ac94baa8ac4e62809d8dc64",
      "716ec00e9588402e987ad302e23acdc0",
      "3af9bde01c5e4f4fb8b99470f4db728c",
      "10459a0de2634185b7fdb633d628e9b1"
     ]
    },
    "id": "vBGueBjwbjXB",
    "outputId": "0ea923fd-cbec-4fdc-bc21-28929772a30c"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading base model mistralai/Mistral-7B-v0.3 in 4-bit and applying adapters from coqa_chatbot_lora\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26a6203a250e421e9e57818a7388267b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "957615421d6848cbab8add7e580082d8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3915ea43b8f8424c88d2b532d04f1b18"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8bd568875e24fb5a921cdf1b1982041"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35dbb886f2cb4207ab4677777f01120c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5b86f5b70f64555a1f71b6e8decd7ea"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Loaded SFT model + tokenizer\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "import random, torch, os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "ds = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-base\")\n",
    "\n",
    "SAMPLE_SIZE = 1000\n",
    "if len(ds[\"train\"]) > SAMPLE_SIZE:\n",
    "    ds_small = ds[\"train\"].shuffle(seed=42).select(range(SAMPLE_SIZE))\n",
    "else:\n",
    "    ds_small = ds[\"train\"]\n",
    "\n",
    "print(f\"Using {len(ds_small)} examples for reward-model training\")\n",
    "\n",
    "class PairwisePreferenceDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, tokenizer, max_length=256):\n",
    "        self.dataset = hf_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset[idx]\n",
    "        prompt = row.get(\"prompt\") or row.get(\"input\", \"\")\n",
    "        chosen = row[\"chosen\"]\n",
    "        rejected = row[\"rejected\"]\n",
    "        text_chosen = (prompt + \"\\n\" + chosen).strip()\n",
    "        text_rejected = (prompt + \"\\n\" + rejected).strip()\n",
    "        enc_ch = self.tokenizer(text_chosen, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "        enc_re = self.tokenizer(text_rejected, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids_chosen\": enc_ch[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask_chosen\": enc_ch[\"attention_mask\"].squeeze(0),\n",
    "            \"input_ids_rejected\": enc_re[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask_rejected\": enc_re[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "REWARD_MODEL_DIR = \"reward_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=1).to(device)\n",
    "\n",
    "dataset = PairwisePreferenceDataset(ds_small, tokenizer, max_length=256)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        input_ids_ch = batch[\"input_ids_chosen\"].to(device)\n",
    "        attn_ch = batch[\"attention_mask_chosen\"].to(device)\n",
    "        input_ids_re = batch[\"input_ids_rejected\"].to(device)\n",
    "        attn_re = batch[\"attention_mask_rejected\"].to(device)\n",
    "\n",
    "        out_ch = model(input_ids=input_ids_ch, attention_mask=attn_ch).logits.view(-1)\n",
    "        out_re = model(input_ids=input_ids_re, attention_mask=attn_re).logits.view(-1)\n",
    "\n",
    "        logits = torch.stack([out_ch, out_re], dim=1)\n",
    "        log_probs = torch.log_softmax(logits, dim=1)\n",
    "        # label=0 means chosen is \u201cbetter\u201d (index=0) by convention in pairwise preference\n",
    "        labels = torch.zeros(len(out_ch), dtype=torch.long, device=device)\n",
    "\n",
    "        loss = - log_probs[torch.arange(len(labels)), labels].mean()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} \u2014 avg_loss={avg_loss:.4f}\")\n",
    "\n",
    "os.makedirs(REWARD_MODEL_DIR, exist_ok=True)\n",
    "tokenizer.save_pretrained(REWARD_MODEL_DIR)\n",
    "model.save_pretrained(REWARD_MODEL_DIR)\n",
    "print(\"\u2705 Reward model saved to\", REWARD_MODEL_DIR)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478,
     "referenced_widgets": [
      "2b9fb9a70ef44cbc8a7d435a0b973680",
      "82f15a91c0b94e9a931d878531195ec7",
      "af65a063ed534a4992dec67a72d6b4a6",
      "ec08de3fe2db4a80a372cfca547dc3b8",
      "8e84f96508504e5280c060316a8aa842",
      "90f2c37eafab4630ad707b8a381e7370",
      "8719680a72114d7cb76026a1d0ccda87",
      "236ab10bd4284961b14c67b39c8a0e7b",
      "35a88a1761e043d082545ca49aef7b6b",
      "9b629cc678aa4af7ae88159d9de6f958",
      "d86ea4ebb58c46c6a42a1482caed5408",
      "338a6076649549d39caa70fef4fa4369",
      "e0b3fdebd69647f1a112c943342f5a41",
      "1d26e1259eda4bd7b6d49ef67e8c6060",
      "aa37e9472da149d3b7790b6e951fc9d8",
      "958ade2d34544a58bfcf52bdc3f05755",
      "db5a4f3eb18341798bb4f1515c1b3d0d",
      "4fc9219056c544bda4faa51dee226c0e",
      "ce1295f3f8b640159f91bc8a66b3ca45",
      "c71da14c9f834df39c1cbf086bd5f3c5",
      "7d002ffff17a4686b455a635ef230b11",
      "ca19a1ea5cc24039b9676f9905d17317",
      "475fdadb747644da94ce45f76daa993b",
      "e3f708afe0f7450c953d4da7e17bac22",
      "e7f82493b86c4ae7aa65d3a498ba8934",
      "7083bf83aed7482492196d54356879ea",
      "fde7a8b6fa5344ec8296465ca97c1b5b",
      "e90ee76a048d438eb8af31aa18dd56af",
      "cfabfd597d5748ffbd453edc3aa40c67",
      "eaa69fdae44f4ef78c54ace91e0b6430",
      "6eaa928849cf4fefaf9a65394b0fcf9b",
      "807c27424c3f45fdbd9e3928e8b2fa5a",
      "1437235bdf5a47e097e19b56dae918b6",
      "ed18b0db96ca46b3a08ce3ca75019481",
      "bce6691a8e0a40ed80e7c84c17809520",
      "d6d18a571956442d86f99b57c9e282e4",
      "66c435e9ade94430abf18923e677e4ad",
      "f8ef468c8eeb419f9ae41da5c38dfe56",
      "c0934235925c40f58fb3864d38b7c06e",
      "e3c7f9953e444155aee359f76f309150",
      "8c1ed99d9efb47178e8f76f270a55693",
      "9828b47537734deaaee5f4e641a967f0",
      "de7cf6231c394ceaa72f5f31983a8391",
      "539b68d7f30341ad94e2f37a6d48fc1d",
      "faf9fda996d541caa662bdcd6940e935",
      "7ae7b0d03dbb4215b9330be0b605ccdc",
      "edf14dec90cc435bb03854717a065d9c",
      "bb289a12994348f89fb5e7259fd2afd6",
      "2a6a5b2d40f04827878305d45b37722d",
      "82a8f142d5e04d53a412217dacddfd50",
      "f7da4c4a8cdb4f16a6a794e60c76a4f0",
      "3a20d9d413924c43aca08bb5bf7f9c17",
      "dc153106e4ec48808cafbe5b20fca613",
      "14ce651ba76c4bf5a9433ba46bffd809",
      "5cea1ea9314d44be89ca16e04c357953",
      "71fde2a4287c410ba88b945c57c462c0",
      "e65b96cda15049178381866f0114b8b4",
      "22a8c5fe1f86424db19e60745414899c",
      "74cbfdd323b74fb497ec9aeaa954d76f",
      "335760bf2e53423aada986d3ebaa3485",
      "17fcc7c7f89f4d23bfd6ec12adcc0a43",
      "54ad3ead60bb40e3bb64976b6c705f27",
      "0697e725e4114a0e8e6f73daba6ff345",
      "215b58b3ced34e4fbff00ad22c7b55be",
      "a3a30b4cac2949639fc1eedf3f98cf5c",
      "6da4bc74cb3746a0b960f9a0d8c54389",
      "e32fa99cf1d5420fb9d8bad6f42c9aa9",
      "067c09944a4245778f369181e033b886",
      "efb8bf83082c4f82ba50551e8115eb81",
      "42f3ade6598e4f26844ffe19849dcaf0",
      "be9223950d404a33b5363cf08b1cb962",
      "ff71831a7e2c436284abf86576256122",
      "45a658df70c64350a65ef8a7fabd73f7",
      "6da3e5cbf46c427899f78a3c76a16a35",
      "1229c2a6dc7649428f2976a8cf8f3e9a",
      "524542c668cc44c9bd49be8a998f8fe8",
      "1c0d5873bf6b4b008642bdaa41a4e286",
      "949b09fb0c224b62a8a21d8be6c7758c",
      "24a959965ee84b56ae1ae6de20772146",
      "9e04871553be4f77bf85ff7aa82da5f5",
      "985470a6317a4b0485ab7717f9a1b248",
      "647946569b65408883767b8c16a29feb",
      "4aad9bbdbb6a43acb97adac5fb8e83ff",
      "c4eae8640d0946908ca089608786935e",
      "8ac8c7e2c7a04b83a7252373d49c33ad",
      "bce5fcfe9a924523aabd1d6190783764",
      "80075e838fef4443b755ae6fe02eeaa8",
      "f80394075c4449ce9c75a1bd80b23986",
      "eeb661613a4348dda82c06cc6ca4214f",
      "de59ad6bdd2b4a72bf7a34a07dde3d35",
      "255c845f6c3448ffba8a3b98792ae563",
      "8df071b42f6d41e09a6aeaa4ae2776ec",
      "d1b2542e72224e87a4f96981d80bbd85",
      "22e06e757fae4b428546143a51aaeb3f",
      "012f8708aba04baa81e9ad352504c42c",
      "5147005bf35042a782c1dc9ef21523cc",
      "768092baf94a4abaa5799d2c65c523ef",
      "6fe61df699d74e6ba35f566cdfa3a2e5",
      "116413e4eaaf4a0bac9a0d3f5efef391",
      "a41ffa26ca064354bfee40fda20b815d",
      "f9802f835faa42c08cda9546740d91a7",
      "42641b625b874547a7fd2d96f86fb135",
      "6fda8b3f01aa4f00920c0cefa84b9a8f",
      "3a1967b5cf844b1e88249d9fd45c22b7",
      "b68632494e114d9893c32b1ff4a23696",
      "856857073e9543e7a7f547b739466c21",
      "960121f654b1476f8b778ed84a71ca8c",
      "8d9bf1026f324e1fbf4a281f49feedbd",
      "e63fb40fb2d74c3fbef1dfc1b33c8aed",
      "aad2d1705e6d48e0a9f5c1ed239aff3d"
     ]
    },
    "id": "mHra7nHmhTcj",
    "outputId": "1b28ca57-5cd9-49c6-a8cd-1840799f6c01"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b9fb9a70ef44cbc8a7d435a0b973680"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "helpful-base/train.jsonl.gz:   0%|          | 0.00/16.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "338a6076649549d39caa70fef4fa4369"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "helpful-base/test.jsonl.gz:   0%|          | 0.00/875k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "475fdadb747644da94ce45f76daa993b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed18b0db96ca46b3a08ce3ca75019481"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faf9fda996d541caa662bdcd6940e935"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using 1000 examples for reward-model training\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71fde2a4287c410ba88b945c57c462c0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e32fa99cf1d5420fb9d8bad6f42c9aa9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "949b09fb0c224b62a8a21d8be6c7758c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eeb661613a4348dda82c06cc6ca4214f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a41ffa26ca064354bfee40fda20b815d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3 \u2014 avg_loss=0.6702\n",
      "Epoch 2/3 \u2014 avg_loss=0.5968\n",
      "Epoch 3/3 \u2014 avg_loss=0.4289\n",
      "\u2705 Reward model saved to reward_model\n"
     ]
    }
   ]
  }
 ]
}